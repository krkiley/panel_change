---
title: "Stability and Change in Personal Culture"
author:
- Kevin Kiley
- Stephen Vaisey
date: "Duke University"
output:
  bookdown::word_document2: 
    fig_caption: yes
    reference_docx: word-styles-reference-02.docx
  pdf_document:
    number_sections: yes
header-includes: \usepackage{longtable}
nocite: |
  @swidler01
bibliography: panel_change_bib.bib
abstract: Models of population-wide cultural change tend to invoke one of two broad models of individual change. One approach theorizes that people actively update their beliefs and behaviors in the face of new information. The other argues that, following early socialization experiences, dispositions are stable. We formalize these two models, elaborate empirical implications of each, and derive a simple combined model for comparing them using panel data. We test this model on 183 attitude and behavior items from the 2006-14 rotating panels of the General Social Survey. Though the pattern of results is complex, it is somewhat more consistent with the settled dispositions model than the active updating model. Most observed change in the GSS appears to be short-term attitude change or measurement error rather than persisting changes. When persistent change occurs, it is somewhat more likely to occur in younger people than older people and more common for public behaviors and beliefs about high-profile issues than private attitudes. We argue that we need both models in our theory of cultural evolution but that we need more research on the circumstances under which each is more likely to apply.
---

```{r setup, include=FALSE}
# Before the first commit, I added "here", changed the load paths with here(), and added the %!in% function

knitr::opts_chunk$set(echo = FALSE)
library(ggdag)
library(ggrepel)
library(here)
library(tidyverse)
'%!in%' <- function(x,y)!('%in%'(x,y))

```

# Introduction

Culture is an important part of social life but cultures are continuously evolving. In 1972, for example, more than 40 percent of US adults supported a law outlawing interracial marriage. Three decades later, this opinion had become so uncommon that the question was removed from the US General Social Survey. How does this kind of cultural change happen? 

Attempts to account for opinion changes in society have produced conflicting theories about the process of opinion formation and the ability of individuals to maintain consistent attitudes. Some models suggest that people lack the cognitive tools to maintain consistent beliefs on social and political issues. As a result, they construct responses on the fly in the interview setting, drawing on ideas from opinion leaders and changing their attitudes as elite discourse changes [@zaller; @converse; @perrinmcfadden]. By contrast, cohort replacement theories posit that people do hold opinions and are unwilling to alter them in the face of societal change, and thus public opinion changes only with generational turnover [@mannheim; @ryder]. Another set of models claim that people hold "a number of real, stable, and sensible opinions about public policy" and change their opinions in response to new information [@pageshapiro: p. xi; @achen1992]. More recently, sociologists have suggested that people attempt to align malleable peripheral beliefs with relatively fixed "core" beliefs using social cues [@boutylinevaisey; @lakoff; @goldbergstein]. 

Despite their diversity, models of aggregate attitude and behavior change often implicitly invoke one of two broad models of individual change with strong connections to theories in cultural sociology. The first of these models is an _active updating_ model that emphasizes the role of changing discourses, environments, and interactions on attitude formation. This model is rooted in a broadly pragmatist approach to action, which claims that contemporary social environments and problems provoke people to adapt their views and make new meaning (e.g., Joas 1996, Gross 2009, Swidler 2001). The second is a _settled dispositions_ model, which emphasizes the continuing influence of durable dispositions acquired early in life. This model has affinities with the Bourdieusian tradition, which de-emphasizes (though does not ignore) the current environment in favor of the "past conditions of production" (e.g., Bourdieu 1990, Vaisey and Lizardo 2016). These two models represent different approaches to understanding how people come to hold diverse forms of _personal culture_, or the declarative and non-declarative attitudes, worldviews, values, dispositions, and associations that manifest at the individual level [@lizardo17].

In this paper, we make these two models of personal culture change explicit, deduce some of their empirical implications, and derive a statistical model for estimating the prevalence of active updating using panel data. In contrast to previous models that tend to assume one of these data-generating processes to measure stability and reliability of estimates over time, our approach separates persisting change from non-persisting change to estimate if there is evidence of individuals in the population making persistent changes in attitudes and behaviors. We then apply this method to 183 items from the 2006-2014 General Social Surveys (GSS). By classifying the pattern of change in personal culture, we can clarify when different accounts of aggregate change are more likely to apply. Because of data limitations, we cannot speak to all types of cultural objects (e.g., music styles, baby names). We do, however, investigate a wide variety of opinions, including views on politics, free speech, race, and gender roles, and practices including socializing at bars or attending church, that are important in contemporary U.S. society.

Our analysis yields several results. First, we find that the majority of what appears to be individual-level change in attitude or practice probably reflects short-term (i.e., non-persisting) change or measurement error rather than actual persistent change. Simply put, there is little evidence that large numbers of U.S. adults changed their beliefs or practices in lasting ways over this period of study. Second, settled opinions vary in how consistently individuals report the same answer. Consistent with theories that argue that people lack clear opinions, some survey items appear to elicit inconsistent or random responses. At the same time, people are consistent on both high- and low-profile public policy items, suggesting a greater degree of "real" attitudes than these theories suggest. Third, the persistent change that we _do_ see in the data is somewhat more concentrated among younger respondents. On several items it appears that younger adults are still in the process of acquiring dispositions and habits they will take into later life. Fourth, we find that changes in social behavior (e.g., church attendance, political party membership, socializing) are more likely to persist than changes in private attitudes (e.g., political ideology), and people are more likely to report these attitudes and behaviors consistently. This suggests that interactional and institutional mechanisms may provide stronger support for lasting change than pressures for intrapsychic consistency.

Our findings offer broad support to theories claiming that cultural change comes through generational turnover rather than persuasion and social influence. However, there is a pattern of exceptions and caveats that can help us understand how institutions and events shape the process of cultural change and that challenge the idea that change in all attitudes follows a similar trajectory over the life course. The pattern of results also supports models of attitude change that put ideological identification at the center of a network of political beliefs and suggest that individuals are more likely to make lasting changes in their partisan identification than to their general political beliefs. We argue that there is a place for both the active updating and settled dispositions models in our theory of cultural evolution but that we need more research on the circumstances under which each is more likely to apply.

# Theoretical Background

## Belief Formation in Cultural Sociology

How does cultural change happen at the individual level? Let us make the question concrete by imagining a person who answers the same question each year for several years. The question could be anything, but assume it is this GSS question: "Please tell me whether you strongly agree, agree, disagree, or strongly disagree [with this statement]: 'a working mother can establish just as warm and secure a relationship with her children as a mother who does not work.'"

How does the respondent formulate a response to that question each time, year after year? To make things as explicit as possible, we can write the data-generating process formally. Although this presentation may make it seem like we are assuming rationality or conscious deliberation, this way of writing the models makes no particular cognitive assumptions. We will explain this in greater detail below. For now, consider the following two simple models:

\begin{equation}
  y_{it} = y_{it-1} + \nu_{it}
  (\#eq:AR)
\end{equation}

\begin{equation}
  y_{it} = U_i + \nu_{it}
  (\#eq:FE)
\end{equation}

These models may seem similar at first glance, but they have different implications for the pattern of individuals' responses we would observe over time. Equation \@ref(eq:AR) represents an _active updating_ model and Equation \@ref(eq:FE) represents a _settled dispositions_ model, as we explain below. Figure \@ref(fig:dag) shows these models in graphical form, which helps highlight their differences. In the next two sections, we consider each of these models and briefly discuss their connections to sociological theories.

[Figure \@ref(fig:dag) about here]

```{r}
library(ggdag)
library(dagitty)
```


## Active Updating Model

Equation \@ref(eq:AR) represents the active updating model. The respondent forms her answer by starting with what she said last time ($y_{it-1}$) and then incorporating any new considerations ($\nu_{it}$). There is no need to remember responses from earlier time points (e.g., $y_{it-2}$) because this information gets folded into the updated response each time. Formally, Equation \@ref(eq:AR) is a Markov model, where future states depend entirely on the current state. This formal property is often assumed to underlie the data generation process in studies of change in and reliability of repeated survey measures [@alwin; @krosnickalwin]. In this framework, we use the term "updating" to refer to the change to a new baseline for whatever reason, not necessarily requiring the incorporation of new or better information.

More informally, this AUM posits a person who is updating her views in the face of social experience. There are formal Bayesian ways of modeling updating, and this model underlies theories of rational updating in the face of new information [@achen1992; @bartelsjackman; @pageshapiro], but we need not rely on any assumptions of rationality, optimality, or conscious thought for this basic process to apply. Following Gross's [-@gross09, pp. 367] pragmatist account, we could instead regard this model as consistent with an "active and creative relation to the world" that "lead[s] actors to see themselves in new ways, to value different kinds of goods, and to become attached to problem solutions that they could not have imagined previously." 

Active updating lies at the heart of most theories that suggest social environments influence individual attitudes and behaviors. When sociologists posit that adults adopt the beliefs and behaviors of their friends [@christakisfowler; @centola; @dellapostashimacy], or that individuals adopt behaviors that they view as consistent with their cultural dispositions [@goldbergstein], they invoke this model. When social scientists argue that people adapt their partisan affiliations to conform to their social groupings, change their ideological commitments to conform to their partisan identifications [@greenetal], change their partisan affiliations to match their ideological commitments [@baldassarigelman; @abramowitzsaunders06], or respond to exposure to diverse opinions by becoming more extreme in their viewpoints [@bailetal], the claim is rarely that these changes are temporary shocks that will revert to a stable baseline over time. Instead, the claim is that the changing social environment changes dispositions, which will then remain stable until the environment changes again. 

Regardless of whether the exact process is rational, heuristic, discursive, embodied, or any combination of these, the key notion is that the actor continues to be influenced by the (social) environment in ways that might lead to long-term, persistent change in beliefs, practices, and identities [@gross09; @degloma]. As the person encounters new considerations throughout her life (e.g., adding working mothers to one's social network, seeing changing media representations of working mothers), she can continue to revise her views.

The AUM makes no assumption about the distribution of $\nu_{it}$. Specifically, it does not assume that $\nu_{it}$ has an expected value of 0, either for any time $t$ or for any person $i$. This leaves open the possibility of a population-wide shift in responses as many people react to the same changes in the environment.

Several theories of cultural change at the societal level require evidence of active updating at the individual level, such as arguments that the individuals in the population are becoming more polarized on political issues [@dimaggio_polarization; @iyengarwestwood], arguments that individuals adjust their political preferences based on the performance of the governing party [@pageshapiro; @bartelsjackman], arguments that new ideas diffuse across the population through person-to-person contact [@centola], and arguments that changes in elite discourse drive change in mass opinion [@zaller]. In the absence of evidence that people change their minds in persisting ways, these theories cannot be valid at the aggregate level, and we must seek other explanations for aggregate changes.

## Settled Dispositions Model

Equation \@ref(eq:FE) represents the settled dispositions model. Here each respondent begins the study period with a set tendency to respond to the question in a particular way ($U_i$). Temporary considerations, like current events, can play a role in what response she gives at each time (part of the $\nu_{it}$), but these considerations have no lasting impact beyond time $t$. As the right panel of Figure 1 makes clear, there is no mechanism by which a particular consideration can "propagate up" into the settled disposition and change the baseline for future responses. Such considerations are thus temporary influences only. At its core, this model reflects the Bourdieusian model of action that emphasizes "the past conditions of production" [@bourdieulogic, pp. 66ff]. In other words, updating happened, but it happened in the past, prior to the time of the study. In this sense, $U_i$ reflects the "habitus." 

The SDM underlies theories that suggest that individuals are stable in their dispositions throughout life or, if they do change, tend to revert back to a relatively stable baseline in short time, including “control” theories such as Identity Control Theory and Affect Control Theory [@robinson2007; @smithlovinheise]. The notion that individuals are stable in their dispositions is commonly associated with cohort replacement theories of attitude change at the population level. These models posit that people hold relatively stable opinions, that few people change their attitudes as they age, and that most change in public opinion must come from older people dying and being replaced in the population with young people who hold different opinions [@mannheim; @ryder]. Vaisey and Lizardo [-@vaiseylizardo], looking at a range of opinion items in the GSS, suggest that population-wide cultural change most likely comes in the form of cohort replacement.

On its face, the settled dispositions model might seem to imply that individuals hold strong, consistent opinions, but this need not be the case. The settled dispositions model is also consistent with theories that suggest that people lack stable opinions and are unable to report them as such in a survey context [@perrinmcfadden; @bourdieu_publicopinion]. These theories tend to focus on questions of public policy, since the act of opinion creation requires more information than individuals typically have [@zaller; @converse]. Such accounts imply that peoples’ responses at any particular time are a deviation from a baseline, with this deviation often assumed to be random and commonly referred to as a form of “measurement error” [@pageshapiro; @converse]. As long as these deviations are random, there is no reason to perceive these changes as a form of updating, even if wave-to-wave differences are quite large.

Like the AUM, the SDM does not require $\nu_{it}$ to be 0 in expectation for the population at time $t$, but it does assume that $\nu_{it}$ has an expected value of 0 within an individual over time. That is, current considerations can move a person from their baseline temporarily, but there is a tendency to "bounce back" to that baseline over time. The SDM thus allows for population-wide shifts in beliefs, practices, or identities at a particular time (temporary period effects), but it assumes that within people these shifts will be erased over time as people return to their baselines.

Like with the active updating model, there are theories of attitude development and change at societal level that would require evidence of the settled dispositions model at the individual level. For example, if people's attitudes change in a way that reflects updating, then it would be wrong to consider their deviations from their average to be "measurement error," and theories that suggest that changes in belief are not real [@pageshapiro] would be unsupported. Similarly, an item would have to be relatively stable for most adults for aggregate cultural change to come primarily through cohort replacement [@ryder]. 

The two general models thus differ fundamentally on their emphasis on the character of personal change. In the AUM, changes tend to persist because they propagate into future responses, shifting the baseline over time. In the SDM, changes tend to revert because each person returns to their baseline. We can therefore summarize the models' implications for individual change as follows: the AUM predicts _persisting change_ whereas the SDM predicts _non-persisting change_.

## Consistency in Response

Neither model makes any assumptions about the magnitude of the variance of $\nu_{it}$, meaning that both models allow for the possibility of either high or low levels of change in responses from wave to wave. This means that we must consider separately the overall _amount_ of change in responses from wave to wave and the _persistence_ of this change. Knowing that there is more wave-to-wave change in one item than another tells us little about how these two items relate to underlying theories of attitude development. However, knowing that two attitudes have the same rate of wave-to-wave change, but that one follows an active updating pattern with little random fluctuation, while the other follows a settled disposition pattern with a high amount of random fluctuation allows us to make more precise inferences about the applicability of different theories to these items. As such, we designate a second term, _consistency_, to reflect this second dimension of change. _Consistency_ here simply refers to the degree that the attitude development process departs from pure randomness.

## Toward Theoretical Synthesis

We do not suggest that all attitudes and behaviors captured by survey questions follow a settled dispositions model or that all display active updating. Instead, we suggest that by classifying the pattern of change at the individual level, we can use that as a tool for adjudicating debates of change at the aggregate level.

The clearest theoretical contrast is between models that assume beliefs are settled during adulthood, such as cohort replacement theories, which would produce a pattern of low active updating, and those that posit that individuals update beliefs throughout their lives, which would produce an active updating pattern. This disagreement thus forms the primary structure of our analysis. However, it is possible that some items display active updating while others do not. There are at least three ways to understand how both models could be present in the population without contradiction: age-based differences, core-periphery models, and public-private differences.

_Age-based differences:_ The concept of a "cohort effect" is that the environment influences the baseline response tendency when a person is young and then stabilizes for the remainder of one's life [@elder; @bartelsjackman]. To put it differently, cohort formation requires an early period of updating followed by a later period characterized by either absolute stability (where the variance of $\nu_{it}$ is low) or by temporary, non-persisting changes that disappear as people revert to baseline.

Items that reflect a cohort replacement pattern should demonstrate low active updating at the individual level for most adults but high active updating for young people, as this is the period most commonly found to be susceptible to attitude change [@glenn; @inglehartbaker; @visserkrosnick; @danigelis]. 

_Core-periphery models:_ A number of theories of attitude development posit that people hold “core” beliefs, which they use to adjudicate peripheral attitudes [@boutylinevaisey; @goldbergstein]. This work has predominantly focused on political beliefs and adjudicating whether people use ideological identity, policy positions, moral beliefs, or partisanship to form their positions on other issues [@lakoff; @greenetal; @kinderkalmoe]. In their analysis of cross-sectional data, Boutyline and Vaisey [-@boutylinevaisey] find support for ideological identification -- assessment of oneself as a conservative or a liberal, not as a Republican or Democrat -- as the "core" belief in the political space. Similarly, Baldassari and Gelman [-@baldassarigelman] find increased alignment between partisan identification and policy positions but little increase in the correlation between specific policy positions over time. They interpret this finding as indicating that "voters are splitting along party lines according to the issues that are most salient to them, while they do not bother to adjust their (weak) preferences on the remaining issues" [@baldassarigelman: pp. 442]. 

The picture that emerges from these previous works is that ideological identity should be a core, if poorly reported, disposition. Changes in ideological identity should be non-persisting, occurring because people either do not fully understand these terms and report their views with error [@converse] or because people bounce around a stable mean, meaning this item should show low updating and medium to low consistency. On the other hand, we should see evidence that individuals adjust their partisan identification to match their ideological identification as they come to find that one party better represents their core positions [@baldassarigelman]. In other words, liberal Republicans should become liberal Democrats, not conservative Republicans. This means that partisan identification should display high levels of updating. Again, this does not mean that many people change, only that changes tend to persist.

Alongside ideological identification, moral issues and general political sentiments might serve as core organizing principles, but what these beliefs are will not be consistent across people [@baldassarigelman]. For example, some people might hold strong, consistent views on abortion while others care about the amount of government intervention in the economy. Because of this heterogeneity, these beliefs should have a moderate level of consistency, since those people who do not value them should report them inconsistently. There should be no evidence of updating in these beliefs, as previous work suggests that people do not bring these attitudes in line with other beliefs, even if they are discordant. 

Peripheral beliefs that "grow" out of core beliefs, such as preferences for government spending on various priorities and specific policy positions, should show some evidence of updating, as individuals attempt to align these with their core beliefs. However, because of the cognitive effort required to map peripheral beliefs onto core beliefs, we generally expect the former to be inconsistently reported [@zaller; @converse]. However, there are conditions that might decrease that cognitive effort and therefore increase the amount of updating and consistency with which peripheral issues are reported, to which we now turn. 

_Public vs. Private Culture:_ A final dimension that likely influences the degree of active updating and consistency of attitude and behavior reports is the publicness of the item, or whether it is in some way externalized in public symbols, discourses, and institutions. The act of opinion construction often taps what Lizardo calls "personal declarative culture," the "explicit, symbolically mediated culture" such as language that people use to reason, evaluate, judge, and categorize objects [-@lizardo17: p. 91]. This kind of knowledge is contradictory and flexible, meaning a person can reach and justify a range of different opinions in response to the same prompt, depending on the circumstances. However, when public culture provides a strong "scaffold" through clear signals of how identities and social locations should influence opinions, it becomes easier for people to maintain consistency [@lizardostrand].

Theories that argue that individuals do not hold consistent opinions also posit that issues that receive significant media attention can be reported more consistently than other issues [@zaller; @converse]. This means a small number of high-profile issues might demonstrate a higher rate of consistency, but we do not expect high rates of active updating for most of these, since signals are consistent over time. However, we do highlight one issue that saw significant change in elite opinion, which should have lead to active updating in the general population. In the time frame we observe (2006-2014), there was a major shift in elite opinion on gay rights. Leaders of the Democratic Party (including President Barack Obama) came out in favor of legalizing gay marriage, and a number of Republican Party leaders also began to express support for gay marriage. For this issue, we expect to find evidence of active updating throughout the population, not just among young people.

Items that tap some public dimension of behavior and attitudes are also likely to show higher levels of active updating because social mechanisms, such as publicly joining a group, can help maintain changes in ways that intrapsychic forces cannot. Any item where the burden of maintaining consistency is externalized and not only “in a person’s head” might demonstrate both higher rates of active updating and greater consistency.

As we noted previously, we do not expect that all items will align with just one model. If we find a diverse array of patterns, with items displaying a range of active updating and consistency, then the above theories provide a window through which to interpret these distinctions. Our goal here is neither to declare victory for one of the theoretical perspectives nor to simply say that all “matter.” Rather, our objective is to improve sociological models of cultural evolution by more precisely specifying when and where different types of processes are at work. We believe achieving a better understanding of these processes will be relevant for many sub-fields of sociology as well as for other social science fields that study changes in beliefs and behaviors.

# Research Questions and Expectations

With these considerations in mind, we ask the following questions:

First, _to what extent are patterns of personal cultural change generally better described by an active updating model or a settled dispositions model?_ Previous work on cultural change using cross-sectional data has suggested that cohort effects are generally more important than period effects in explaining broad cultural change [@vaiseylizardo]. This implies that, in the repeated measures data on adults we will use here, we should find that the settled dispositions model performs better on most items because cohort formation should be (mostly) complete.

Second, _is there evidence that younger respondents are doing more active updating than older respondents?_ In a sample of adults, the possibility exists that cohort formation may be complete for most beliefs and behaviors before the study period (i.e., before age 18). However, if some cohort formation is still occurring among younger respondents, we should see that evidence consistent with the AUM is disproportionately located among younger respondents.

Third, _are there systematic differences in item content between questions that exhibit different levels of active updating and consistency?_ The preceding sections have made some predictions based on existing literature, but we cannot enumerate predictions for all sorts of beliefs and behaviors. As we note, our approach is to use these theories as a lens through which to interpret the overall pattern of results. 

# Analytic Strategy

To investigate these ideas empirically, we examine 183 survey items from the 2006-2014 General Social Survey panels in search of evidence in favor of an active updating model. This period of the GSS contains three different three-wave panels, each of which surveys a sample of adults three times over a four-year period (e.g., 2008-2010-2012). Three waves of data is the minimum amount needed to compare the predictions of the active updating model and the settled dispositions model. We discuss item selection below. While a broader range of years would be preferable, the panel component of the GSS began in 2006 and was discontinued in 2014, so these years represent the full range of what we could analyze using the GSS.

## Statistical Model

### Basic Models

Our main goal is to estimate separately the amount of active updating and the amount of non-persisting change in responses over time. We first consider measuring the amount of active updating. Our two different models make different predictions in the three-wave panel context. The AUM makes the following prediction for wave 3: 

\begin{equation}
  E(y_{i3}) = y_{i2}
  (\#eq:AUM2)
\end{equation}

That is, the AUM predicts that a respondent's most recent response is the best available predictor of her next response, and that wave 1 carries no additional information in predicting wave 3 once we control for wave 2. If change is persisting, then our best guess is that a person's response will be close to what they said last time, and previous responses will provide no additional predictive power.

The SDM makes the following prediction:

\begin{equation}
  E(y_{i3}) = U_i
  (\#eq:SDM2)
\end{equation}

Since the best estimate of $U_i$ is the mean of the respondent's two previous answers, we can rewrite the SDM prediction as:

\begin{equation}
  E(y_{i3}) = \frac{y_{i2} + y_{i1}}{2}
  (\#eq:SDM2B)
\end{equation}

That is, the SDM predicts that the average response of previous waves is the best predictor of the next response. If change is non-persisting, then taking the average of the last two responses will be our best guess about a person's underlying position.

### Combined Model

Both of the models above include $y_{i2}$ as a predictor of $y_{i3}$, but only the settled dispositions model includes $y_{i1}$ as a predictor. If the SDM is correct, $y_{i1}$ should be just as predictive as $y_{i2}$ because both are (on average) equally informative about the respondent's stable disposition. Therefore, to test for evidence of active updating we use a model that evaluates whether $y_{i2}$ carries any additional predictive power over $y_{i1}$. If the two previous estimates are equally predictive, then we can be relatively confident that the data we observe came from a settled dispositions model. However, if $y_{i2}$ is a better predictor of $y_{i3}$ than $y_{i1}$ is, this provides evidence that some respondents engage in active updating. We use the following non-linear model to estimate the relative influence of $y_{i1}$ and $y_{i2}$: 

\begin{equation}
  E(y_{i3}) = \alpha + \phi\beta y_{i2} + (1-\phi)\beta y_{i1}
  (\#eq:MODEL)
\end{equation}

Rather than generate separate coefficient estimates for $y_{i2}$ and $y_{i1}$, this model generates two parameter estimates of interest: $\beta$, which captures how well any combination of previous waves predicts a person's response at wave 3, and $\phi$, the relative proportion of wave 3 explained by wave 2 compared to wave 1. If the Settled Dispositions Model is the preferred data-generating process for an item, then both $y_{i2}$ and $y_{i1}$ should be equally predictive of $y_{i3}$, and $\phi$ will equal .5, meaning the best estimate of wave 3 is a function of the mean of previous waves, consistent with Equation \@ref(eq:SDM2B). If the active updating model is present in at least some respondents and wave 1 provides no additional predictive power when we control for wave 2, then $\phi$ will increase toward 1 to converge with Equation \@ref(eq:AUM2) in certain circumstances.

Our estimates of $\beta$ provide a measure of the consistency of individuals' responses, contingent on the degree of active updating. We can think of this parameter as analogous to an $R^2$ measure in a traditional linear model, capturing the total "predictiveness" of the model. If individuals pick a random response at each wave, the best predictor for a person at wave 3 will be the sample average, and $\beta = 0$. If there is little random fluctuation between waves, once the amount of active updating is accounted for,  $\beta$ will approach 1.

### Comparison to Other Approaches

Our model is not the first to measure stability and change in panel data, but existing models make assumptions that eliminate the distinction between data-generating processes we seek to test. Hout and Hastings [-@houthastings] use a hierarchical model to measure reliability in GSS responses. This model assumes that there is no change in the underlying latent item other than wave-specific period effects (akin to our settled dispositions model), so the design precludes the possibility of quantifying the level of active updating in an item over time, assuming that this change is just measurement error. These authors also test a structural-equation model designed by Alwin [-@alwin] and Heise [-@heise] that assumes the process that generates the data is the Markovian active updating process we outline earlier. While this approach gets closer to our model by generating a parameter for stability and reliability, it would require us to make an assumption that the amount change is consistent across waves. This approach also combines persisting and non-persisting change into two similar but distinct kinds of change: "structural" and "non-structural," both of which can be persisting and non-persisting. This distinction, while important for some theoretical questions, is not our focus.

A number of other approaches seek to understand the consistency of latent beliefs by combining and scaling responses to questions that represent the same latent concept [@ansolabehereetal], assuming that wave-to-wave changes in responses tend to represent measurement errors around a "true" latent belief. This raises the distinction between the _stability of a belief_ and the _stability of a survey question response_. Since we at times invoke both these models, we include in our analysis several composite scales of related items. If wave-to-wave changes in survey responses are non-persisting measurement errors, then scales should have higher consistency than the measures they comprise, but we should see no difference in their levels of active updating.

Another possibility is that participation in the survey itself produces change or stability, referred to as panel conditioning bias [@warrenhalpernmanners; @ohetal]. While Warren and Halpern-Manners [-@warrenhalpernmanners] outline several forms of panel conditioning, we can group these into two broad patterns. One set of patterns suggests that people’s responses become more consistent over time as participation in the survey forces them to crystallize their beliefs, seek out new information that helps them form beliefs, realize their beliefs are out of sync with the general population, or learn to “game” the survey to get through it faster. If this were taking place in the GSS, it would result in a pattern of high active updating and high consistency, as respondents would change between waves 1 and 2, and wave 2 would become a better predictor of wave 3.

We do not view this as a problem for our theoretical models. If people change their attitudes or behavior as a result of participating in a survey, they are conforming to the theoretical active updating model, being open to change throughout their life course, and the source of that change is irrelevant. This might lead to a higher estimate of active updating than we might observe in a population that did not take the survey, which would hinder our ability to extrapolate our findings, but would still provide evidence that people update beliefs over time.

A second form of panel conditioning posits that people exhibit low levels of updating because of commitment bias, or an attempt to maintain consistency in their responses over time, even if they actually change. In this scenario, individuals respond to a question at wave 1 and give the same response in subsequent waves, even if their true beliefs or positions change. This would be problematic for our study, as it would under-estimate the amount of real change in the population. However, if this is the case, we should observe no active updating in responses and high levels of consistency, as it would be illogical for individuals to report random changes if they were attempting to maintain consistency.

Finally, a number of approaches exist for evaluating theoretical process of belief formation and change for the population, such as examining the association between theoretically related values [@baldassarigelman; @boutylinevaisey], or by looking at changes in the distribution of responses over time [@dimaggio_polarization]. These tools are well designed to address the questions they set out to answer. However, since our theoretical questions focus on the process of belief change within individuals, these do not speak to our core concerns.

### Limitations of the Method

Three challenges limit our ability to evaluate the presence of settled dispositions and active updating models using our approach and therefore limit the conclusions we can reach. The first is that our model is designed to allocate variance explained to each of the prior waves rather than to assign probabilities to each data-generating process. Because of this, a few individuals making large persisting changes can inflate the $\phi$ estimate even if most individuals make small non-persisting changes.

The second is measurement error, which is a form of non-persisting change. For some researchers, measurement error represents the inconsistency that results from constructing responses anew each wave [@zaller; @converse], and in that case it should not be considered "error" so much as an indicator of that process at work, since there is no "true" item to measure. For other theories, measurement error reflects individuals' inability to accurately report their response. It is also possible that measurement error reflects errors of selection and interpretation, such as misunderstanding the question or incorrect coding.

Because measurement error looks the same as non-persisting real change (and because the latter is sometimes interpreted as the former), $\phi$ estimates will be biased toward .5, since responses with error would be random departures from baseline. There is evidence that many of the items explored in our analysis are measured with significant error [@alwin; @houthastings]. On the other hand, previous studies of reliability tend to conflate measurement error and non-persisting real change in attitudes, meaning that while we might have good estimates for the combination of these two processes, we cannot separate them. Because of measurement error, it is unlikely that $\phi$ and $\beta$ will reach 1 for any item, even if the underlying process is fully based on active updating. 

The third challenge of our analysis is that we focus on predicting wave 3. If individuals have a high likelihood of changing between waves 2 and 3, our ability to predict responses at wave 3 will be limited and $\beta$ will be low. Our model relies on the assumption that "persisting" change is relatively rare and that individuals who change between waves 1 and 2 do not also make persisting changes in the opposite direction between waves 2 and 3. If the rate of active updating is so high that individuals make changes between each wave, then the model becomes indistinguishable from the settled dispositions model with high measurement error, and it may not be reasonable to consider this sort of change "persistent."

In addition to these three challenges, there are two forms of change that our model is not well designed to account for. The first is a uni-directional shock to the population. Since our model includes an intercept, changes that shift all responses toward one end of the scale are absorbed into that term and not accounted for in our $\phi$ estimates. The second is change in the variance of responses. If all individuals shift outward or inward toward the population mean but maintain their relative position in the overall distribution, this change will be absorbed into $\beta$ but not enter into $\phi$.

Despite these limitations, the model is capable of detecting the presence of persisting change even in the presence of high levels of measurement error. Because of this, it is best to think of our approach as seeking any evidence in favor of active updating, rather than allocating probabilities to each model. We can only detect whether there is any evidence of persisting belief changes, and therefore whether there is any evidence that active updating is taking place in the population.

## Analysis Steps

Our analysis proceeds in three steps to answer our three research questions. First, we evaluate the overall evidence in support of the active updating model. To do this, we compare for each item the Bayesian Information Criteria (BIC) of a model estimated using Equation \@ref(eq:MODEL) with a free estimate of $\phi$ to a model that constrains $\phi= .5$. We calculate the posterior probability that the model with the free parameter fits the data better. If the model with the constraint is preferred, then we conclude that both wave 1 and wave 2 are equally good predictors of wave 3, meaning there is no evidence that respondents are actively updating on that item.[^link]

[^link]: All data used in this analysis is publicly available through the General Social Survey at the National Opinion Research Center at http://gss.norc.org/. R code for how we cleaned the GSS panels, all analyses performed in this paper, and all figures created in this paper can be found at http://github.com/krkiley/panel_change.

Second, for variables that show at least some evidence of active updating ($\phi > 0.5$), we ask whether the persistent change is concentrated among younger respondents. To test this, we re-estimate our original model and allow $\phi$ to have different values above and below a given age cutoff. Rather than test a single age cutoff, we again use BIC comparisons to evaluate whether including the dummy variable improves the model fit using a cutoff of every age between 20 and 45. We test a range of cutoffs to ensure robustness of the overall pattern to specific ages.

Finally we consider whether there are any meaningful patterns in the relative distribution of evidence for active updating across variables as suggested by existing theories. Although, as we discussed above, previous work gives some indications about what we might expect, the approach here will necessarily be inductive.

## Item Selection

To test our model on as broad a range of items as possible, we sought measures of attitudes, beliefs, self-assessments, self-perceptions, and social behaviors that were asked in three waves of the GSS panels. We excluded from our analysis questions that focused on demographic characteristics (marital status, household size, region, gender, race, ethnicity), work activity (employment status, income, hours worked, size of workplace), objective socioeconomic status (years of education and highest degree, home ownership), and evaluations of a respondent by the interviewer. We follow Hout and Hastings [-@houthastings] and group questions into 15 categories based on subject material. Questions in the same category tend to be asked in the same block during the survey and have the same structure, such as questions about confidence in institutions, questions about government spending, and questions about social life. 

We also follow Hout and Hastings [-@houthastings] in recreating common scales about gender roles, access to abortion, and social trust. This includes a six-question scale of support for abortion and a seven-question scale which includes the question asking about abortion under any circumstances ("abany"). We use Smith's [-@smith97] scale of "misanthropy" by combining questions about how helpful, fair, and trustworthy people are. We use four questions to create a scale of gender role attitudes [@cotterhermsenvanneman]. Like Hout and Hastings, we combine civil liberties items into six scales about the freedom of atheists, communists, militarists, racists, and, in the 2010-14 panel, Muslim clergy. We combine four parallel questions about how frequently individuals socialize to create a "social life" scale. We combine four questions about support for suicide under different circumstances. We also created a scale of support for police use of violence against criminal suspects by combining five binary questions about the conditions under which individuals support police use of violence.

In total, we test the model on 183 GSS items, including the composite scales.[^coarsened] For each question, we use all cases for which the respondent gave responses in all three waves. Models are estimated using weights that account for the GSS's sampling design as well as non-response adjustment.

[^coarsened]: To ensure that our estimates of $\phi$ are not simply artifacts of response scale construction, we estimate the model on coarsened versions of items, generated by collapsing responses to questions with more than three response options into scales of two or three response options. These results are reported in Appendix B.

# Results

```{r, message = FALSE, warn = FALSE}
load(here("data", "results_df.Rdata"))
load(here("data", "attitude_vars.Rdata"))


label_vars <- res.df %>%
  filter(var %in% c("intlblks", "confed", "selfhunt", "socbar")) %>%
  left_join(attitude_vars)

#create a list of variables that display updating
aum_vars <- res.df %>% filter(aum_pref == 1)
aum_vars <- aum_vars$var


```


Our model estimates two parameters of interest for each GSS item: $\beta$, our measure of consistency, captures how well any combination of previous waves predicts a person's response at wave 3. High values of $\beta$ indicate that individuals are relatively consistent in their responses, once we control for the amount of active updating. Our measure of active updating, $\phi$, captures the relative proportion of wave 3 variance predicted by wave 2. If responses are generated through a true settled dispositions model, then $\phi$ will be .5 (i.e., both wave 1 and wave 2 are equally good predictors of wave 3). As the evidence of active updating increases, $\phi$ will increase toward 1. Both $\phi$  and $\beta$ equaling 1 would indicate that all individuals who changed between waves 1 and 2 persisted in their change, that an item was measured with no measurement error, and there was no additional change between waves 2 and 3.


## Evidence for Active Updating

To evaluate the evidence in favor of the active updating model, we compare for all 183 items the Bayesian Information Criteria (BIC) of a model with a free estimate of $\phi$ to a model that constrains $\phi= .5$. If the model with the constraint is preferred, then there is no evidence that respondents engage in an active updating process with respect to that item.

Figure \@ref(fig:phihist) plots the distribution of $\phi$ estimates for the 183 items evaluated in this analysis and the posterior probabilities that the model without the constraint fits the data better, generated by comparing the BIC from models with and without the constraint.

[Figure \@ref(fig:phihist) about here.]

On the left side of the figure, we see that the majority of $\phi$ estimates fall between .5 and .6, meaning that wave 2 is only a slightly better predictor than wave 1 for most items. This suggests that if active updating is happening in these responses, it is relatively infrequent or small compared to temporary change and measurement error. 

To provide a concrete example, consider the GSS question that asks respondents whether they think it should be possible for a woman to receive a legal abortion if she became pregnant as a result of rape, to which individuals can respond either "yes" or "no." This produces a $\phi$ estimate of 0.62, above the 75th percentile of all $\phi$ estimates. Of the 2259 people who responded to the question in three waves, 257 changed between waves 1 and 2. Under the settled disposition model, these responses would reflect either measurement error or a temporary shift at either wave 1 or wave 2, and we would expect that about 50 percent or 129 individuals would maintain the same response into wave 3. Only 147 of the 257 people (57 percent) who changed between waves 1 and 2 maintained the same response at wave 3. Therefore, we only have evidence that about 18 individuals (less than one percent of the sample) showed evidence of persisting change. 

Considered this way, the majority of GSS items demonstrate persisting change at a rate of less than one percent of the total sample, and none shows evidence of persisting change greater than 5 percent, with confidence in the leadership of the executive branch of the federal government, confidence in banks and the financial system, and the respondent's belief about whether they will be able to find a good job topping the list. In other words, even for items that show strong evidence of some active updating, the overall amount of attitude change in the population is likely small.

The right side of Figure \@ref(fig:phihist) shows that although the majority of items prefer the free parameter, 75 items (about 40 percent of the total) prefer the constraint, meaning these items show no evidence of active updating over this period. That is, although respondents might give different answers to these items in any particular wave because of measurement error or a transient change of opinion, they tend to revert to their previous position. This group includes many items about abortion, civil liberties, confidence in institutions, and views on race and gender.

We will discuss in more detail below how different items perform. To answer our first question, however, we need only focus on the overall distribution. Forty percent of items show no evidence for active updating, and among items that do show some evidence of persistent change, very few come close to approaching 1. This means that for almost all items, measurement error or non-persistent change tend to be much more common than persistent change. We can only be really confident in detecting substantial amounts of persistent change (greater than 2 percent of the population) among a small minority of items, perhaps 1 in 5. This means that most of the "change" that shows up in the GSS panels reflects some combination of measurement error or non-persistent change.

## Age Heterogeneity

Our second research question asks whether there is evidence that younger respondents update their views more than older respondents. Although it's impossible to determine what proportion of people are following each data-generating process, it is possible to compare the age distribution of evidence for updating in each item.

Of the 108 items that showed any evidence for active updating in the last section, 22 showed differential effects of age for more than 50 percent of cutoff ages we tested, meaning the majority did not. Figure \@ref(fig:agegroupcomparison) plots the estimates of these 22 items for individuals above 30 and individuals equal to or below 30 to get a sense of the magnitude of difference between older and younger individuals on these items.

[Figure \@ref(fig:agegroupcomparison) about here.]

The majority of items that show evidence for age concentration show that active updating is more prevalent among younger respondents than older respondents. These items include views on affirmative action, women in the workforce, and politics; several civil liberties items; general views of whether people can be trusted; and views on whether doctors should let terminal patients die. These items tend to be in subject areas where a large proportion showed no evidence of active updating, which suggests an overall trend of these views being formed earlier in life (i.e., prior to becoming eligible for the GSS at 18) and remaining relatively stable over time.

For some items, such as whether individuals can be trusted, political views, whether physicians should allow terminal patients to die, and whether companies should make special efforts to hire and promote women to address past discrimination, all evidence of active updating disappears for people over 30. This suggests that these items follow an "impressionable years" pattern, where early adulthood is a time when these opinions are still malleable, but beliefs quickly harden into "durable dispositions" [@vaiseylizardo; @krosnickalwin; @alwinkrosnick]. For other items, such as how important people believe it is for children to be popular and views on how much the government should spend on health care, there is still evidence of active updating in older individuals even though it is substantially less than for younger individuals. This is consistent with the "increasing persistence" hypothesis, where attitude change gradually becomes less likely as individuals age [@glenn; @inglehartbaker].

Eight items show a negative effect of being below the age cutoff on the $\phi$ value, meaning that younger people showed _less_ evidence of active updating than older individuals. These items include how often individuals were active in religious activities, views on suicide in the case of bankruptcy, and views on whether aging parents should live with their children. Some of these items might be things people are not forced to consider until later in life and as a result do not form clear opinions on while young. This pattern where older individuals change their attitudes and behaviors at higher rates than younger individuals is somewhat unanticipated in the attitude change literature [@visserkrosnick; @danigelis], and suggests greater heterogeneity in the relationship between age and attitude change than previously theorized.

The remaining 86 items (just under half of all items explored here) show evidence for some active updating but do not show consistent evidence for age heterogeneity, suggesting a more complicated relationship between age and attitude change than previously theorized. However, this does not mean these show strong evidence of an active updating model. These items may simply be susceptible to updating for a small proportion of the population.

## Item heterogeneity

While 40 percent of items show no evidence of active updating, and those that do show evidence tend to show only weak support for active updating, it is difficult with just these findings to draw any broad conclusions about how these results speak to theories of attitude development and change. Here we bring in our second dimension of attitude change, consistency in responses, to clarify the overall pattern. 

Figure \@ref(fig:phibetascatter) plots the $\phi$ and $\beta$ estimates for items shaded by whether they preferred the $\phi = .5$ constraint or not and label a few items that stand out. Items tend to prefer the $\phi=0.5$ constraint for a combination of two reasons: because wave 1 and wave 2 have equal predictive power ($\phi$ is close to .5) or because the measure is so unpredictable ($\beta$ is low) that neither wave 1 nor wave 2 has much predictive power, making any observed active updating close to meaningless. 

[Figure \@ref(fig:phibetascatter) about here.]

Items showing evidence of active updating tend to have $\phi$ estimates greater than .55, and most have $\beta$ estimates greater than .6. A small group of variables, including confidence in the leadership of the executive branch of the federal government have low $\beta$ estimates, meaning that prediction at wave 3 is difficult, but have large $\phi$ estimates, meaning that wave 2 is still a better predictor than wave 1. 

Which items show the strongest evidence for active updating? There is no way we can discuss all 183 items in detail without the discussion becoming tedious. Although we include $\phi$ estimates for all items in Appendix A, Figure \@ref(fig:summary) summarizes the distributions of $\phi$ by the content of the question. We constrain items that showed no evidence of active updating to $\phi = .5$. In addition to showing the median and interquartile range of each distribution, the figure also highlights the item in each group that shows the greatest degree of evidence for active updating. 

[Figure \@ref(fig:summary) about here.]


There is a lot to process, even in this summary figure. The main takeaway is that, even for items that show some evidence for active updating, the values of $\phi$ are still quite low. Only two groups of items have median $\phi$ values above $0.6$: public spending and religious activity. In general, then, it is accurate to say that most of the "change" measured by the GSS is not persistent but some combination of measurement error and short-term fluctuations.[^error]

[^error]: While we cannot control for measurement error in our analysis, we can take steps to mitigate its impact. Appendix B presents results comparing items with more than three scale points to coarsened versions of these question with either two or three scale points. As noted previously, low measurement error might be a reasonable assumption for some items. Previous studies using different approaches to measuring the reliability of survey reports suggest that some items captured in our study, such as whether a person owns a gun, are measured with a high degree of reliability ($> 0.9$) [@houthastings]. For other items, such as confidence in the leadership of major companies ($\phi = .58$), reliability might be as low as 0.5. There is very little correlation ($\rho = .165$) between our $\phi$ estimates and reliability estimates.

Consistent with the findings of Vaisey and Lizardo [-@vaiseylizardo], we see that more than half of items in the gender, family, race, sex, civil liberties, and confidence in institutions groups show no evidence for updating (see Appendix B). These categories also contain several items that show evidence of active updating in younger cohorts, suggesting that these items became settled by the time respondents entered the GSS sample. Views on these issues are likely shaped by early socialization experiences and mostly settled by the time a respondent reaches adulthood. This means that, for most of these items, social change must occur through cohort succession rather than through individual change.

There are several exceptions to this general pattern, however, even in categories with otherwise low $\phi$ values. Items with the largest values generally have one or more attributes in common. We consider these attributes to give some general impressions of the pattern.

Some of the high-$\phi$ items rely on _external mechanisms_ that help maintain them. If a person starts going to church or starts socializing with friends at a bar, she builds social networks that make this behavior more likely to continue. This is clear when contrasted with how often individuals socialize with friends, relatives, or neighbors, which are more nebulous questions that display less active updating. Switching political parties (which involves changing public registration) is a more persistent change than changing political ideology (which can happen privately in the mind). Owning a gun has a high $\phi$ value because a new physical object either enters or leaves the person's possession. 

Other high-$\phi$ items have a _changing referent_. That is, although the item wording is the same, the object to which the question refers may change between survey waves. The most obvious example of this is the item about confidence in the executive branch of the federal government (which has the highest $\phi$ value of all items in the analysis). The president changed between the 2008 and 2010 waves of the GSS, meaning that the question no longer referred to the same administration. If we generate estimates for this item for each of the three panels (2006-10, 2008-12, and 2010-14) for the "confidence in the leadership of the executive branch of the federal government" item, it is only for the middle panel (2008-12), where the president changed between waves 1 and 2, that shows significant evidence of persistent change ($\phi = .95$, $\beta = .51$). In the 2006-10 panel, waves 1 and 2 have almost no predictive power ($\beta = .10$). For the 2010-14 panel, which takes place entirely during the Obama administration, $\phi$ moves much closer to .5 and predictive power increases ($\phi = .57$, $\beta = .65$).

Likewise, all public spending items refer to whether we're spending "too much, too little, or the right amount" on different areas. The change of administration and changing federal spending policies likely affected these items. The same applies to most of the questions about subjective SES, where the respondent is asked questions about her personal financial or work situation (which changed for many Americans during the time of the study due to the Great Recession). If the environment is changing we should see exactly this sort of pattern.

Perhaps the most striking pattern in our findings pertains to questions about _gay rights_. There are 6 items that ask about some aspect of gay rights, and all show evidence for active updating. Questions about civil liberties for gays and about gay marriage are the highest in their categories. The huge public and political salience of this issue throughout the study period likely made this issue one where more people than usual were open to revising their views. This pattern is consistent with Zaller's [-@zaller] argument that highly salient issues where elite opinion shifts can lead to large changes in public opinion.

A few items lack external mechanisms, represent forms of private culture, and did not achieve salience during this period, but still display active updating, including some views on abortion and the morality of different forms of sex. We address these items in greater detail in the discussion section.

## Political Beliefs

Because theories of public opinion formation and the development of political beliefs form the bulk of the theoretical tension that frames this analysis, and because many of these beliefs display evidence of active updating, we examine these beliefs in greater detail than other items. Figure \@ref(fig:polvariables) plots the $\phi$ and $\beta$ estimates for questions about political identity, the role of government, and specific policies. We break these items up into categories and remove a few items for ease of viewing.

[Figure \@ref(fig:polvariables) about here.]

There are several notable features of the figure. First, political party affiliation is a clear outlier, with greater consistency and greater active updating than other items. In contrast, questions asking about specific public spending priorities tend to have low consistency compared to other items. Political views – including ideological identification (Named “Political views” in the figure) and general views of the role of government ("Gov't do more or less", "Gov't reduce inequality") – display higher consistency than specific policy questions but weak evidence of active updating. It is important to restate that for political views, all evidence of active updating disappears by the time individuals reach 30, and individuals become more consistent in reporting their ideological identity as they age.

While people tend to be inconsistent in their responses to spending priorities, views on other policy questions with both high and low salience are reported quite consistently. Views on abortion, especially when considered as a scale, are consistently reported. As with all other scales, aggregating the composite items increases consistency but does not affect the estimate of the amount of active updating, validating our method's ability to separate persisting and non-persisting change. As discussed previously, views on gay marriage display high levels of active updating. In contrast, the item asking about support for legalizing marijuana use is reported with consistency but weak active updating. This is notable, as public opinion and policies regarding both have shifted considerably in recent years. Previous work suggests that change in both could be driven by the same underlying process [@schnabelsevell]. Our findings suggest that, at least in recent years, many individuals have changed their views on gay marriage, but changing views on marijuana have been driven primarily by cohort replacement. 

# Discussion and Conclusions

This study was motivated by a theoretical contrast in cultural sociology between the settled dispositions model (SDM), which emphasizes the power of the past, and the active updating model (AUM), which emphasizes contemporary meaning making. These two models of individual change are implicit in analyses of belief change at the society level, but they are rarely compared empirically. We asked three general questions in light of this distinction and developed an empirical approach to adjudicating (albeit imperfectly) between these models. We now revisit our research questions to summarize what we have learned.

First, _to what extent are patterns of cultural change generally better described by an active updating model or a settled dispositions model?_ In general terms, consistent with previous research (e.g., Vaisey and Lizardo 2016), we see a greater degree of evidence in support of the settled dispositions model. Around 40 percent of all items show no evidence for updating. For the items that do show evidence of active updating, the overall rate of persisting change in the population is likely low. For most items measured by the GSS, less than one percent of the population appears to make any persisting change in their views in a two-year period, and most changes appear to be short term or random deviations. What that means in practice is that knowing what a person said two years ago provides almost no better prediction of their current views than knowing what they said four years ago. Unfortunately, because of measurement error, we cannot be sure exactly how much updating there is. But the average level of updating for most views appears to be low.

Second, _is there evidence that younger respondents are doing more active updating than older respondents?_ For a limited subset of items, there seems to be evidence that younger respondents are updating their views whereas older respondents are not. This is consistent with a "cohortization" model that views young respondents as susceptible to updating shocks and older respondents as relatively insensitive to such shocks (see e.g., Bartels and Jackman 2014). Because the youngest respondents in the GSS are 18 years old, we may lack the ability to detect updating that occurs even earlier, so this is probably an underestimate. This may be the case for the roughly 70 items that show no evidence of persistent change over time. Overall, however, there is significant heterogeneity in the relationship between age and attitude and behavior change.

Third, _are there systematic differences in item content between questions that are better described by each model?_ With 183 items tapping very different kinds of opinions and demonstrating a range of active updating and consistency, there is no one overall pattern of attitude change in the population. We find patterns of responses that provide a range of support for diverse theories of attitude formation, which we discuss below. At the same time, our results are consistent with some general expectations about updating. Questions with public (or otherwise changing) referents and questions tapping high-salience topics over the study period (such as gay rights) showed the most evidence for active updating. Items assumed to be "peripheral" beliefs, such as specific policy questions, also showed evidence for updating and low consistency. Most items about gender, family, race, and institutions showed the least evidence for updating, suggesting most people's views on those topics are settled by the time they turn 18. 

There are a handful of items that demonstrate active updating and enough consistency to merit further consideration, but are not easily explained by theoretical mechanisms outlined so far. These include questions about abortion in the case of rape or poverty, the morality of premarital and teen sex, the ideal number of children in a family, and whether children should obey adults or think for themselves. These items did not achieve high salience during the time of the study and there were not, to the best of our knowledge, clear changes in elite opinion on these issues. This suggests additional mechanisms that can drive persisting change at the individual level, such as exposure to these ideas through mass media or by directly interacting with people in these groups. In the case of questions about children and family structures, it might be the experience of having children that leads to changes in these attitudes. It is important to note that even though these items demonstrate active updating, it is a small proportion of the population that are changing their views during the study window. 

The overall pattern of results, while diverse and at times hard to reconcile, does shed light on several theoretical debates. We now consider these implications.

## Implications for Cultural Sociology

In the domain of cultural theory, our findings support the view that a great deal of cultural change happens slowly through the mechanism of cohort succession. Most beliefs about gender roles, sexual morality, and abortion appear to be settled by early adulthood. The settled nature of these beliefs is often coupled with a high rate of consistency, suggesting that individuals truly hold these beliefs or at least have sufficient external support to consistently report them over time. In contrast, many views about race were so inconsistent that it would be difficult to call them either settled or updating. Even those items that did display strong evidence for active updating (e.g. "whites rich or poor" and "whites work hard") were still hard to predict wave after wave. 

Our results suggest that one reason attitudes are largely stable is because most issues simply do not reach the level of salience necessary to shift opinions. In contrast to other beliefs, the pattern of findings for gay rights show that a high degree of public salience and social movements can accelerate change by encouraging people to update their views. By definition, salience is a limited resource, meaning only a few beliefs and behaviors could change at this rate during any given period. The baseline process of attitude change appears to be more consistent with a model that shows that people do not really change; rather, they die and are replaced by cohorts with different views. This general model is more consistent with a Bourdieusian theory that emphasizes the "conditions of past production" rather than processes of active meaning construction with little long-term memory.

While the dominant pattern is stability during adulthood, the results suggest greater heterogeneity in the relationship between age and attitude change than what is emphasized in existing theories. The most prominent and well supported theories of attitude change suggest a peak of susceptibility to attitude change early in adulthood and either a rapid or gradual decline in attitude change with age [@alwinkrosnick; @visserkrosnick]. An additional view, the "life stages" hypothesis, suggests a similar pattern with a surge in attitude change late in life [@visserkrosnick]. While this age-related decline appears to be true for many political attitudes, the pattern is not nearly as consistent for other kinds of attitudes. Some items, such as views on the Bible, suggest equal openness to attitude change as individuals age. Others, such as views on most abortion questions, suggest that early adult socialization is so strong that lifetime opinions are settled by the time most people reach even 18 years old. 

For some beliefs, such as whether aging parents should live with their adult children and whether divorce laws are too lenient, persistent change becomes more common with age, a pattern that is not accounted for in any major hypothesis about the relationship between age and attitude change. This pattern suggests that the salience of an issue can matter at the individual level, as well as the societal level. Rather than supporting a single theory linking age to attitude change, our results call for more work linking attitude content to social factors that encourage openness to change at different ages. Rather than assuming that "attitudes" in general are more or less likely to change at particular ages, we should explore the relationship between age and stability for a range of attitudes. Doing so will expand our understanding of the institutional and developmental factors that that give rise to stable or variable attitudes [@howekrosnick]. Recent work that has attempted to provide social explanations for (mostly political) attitude stability in middle age is an important step in that direction [@eatonetal; @vissermirabile].

## Implications for Political Sociology

A major takeaway of our analysis is that ideological identity (identity as a liberal or conservative, and the extremity of this identification) was in all practical terms stable for individuals over 30. Respondents might express different positions from wave to wave, but in guessing what a person will say in the future, we are better off guessing the mean of their previous responses than their most recent response. While our sample does not cover a large enough window of time or the life course to say for certain whether this represents a regular pattern (perhaps there is some period-specific reason that younger individuals in our data changed while older individuals did not), the pattern is consistent with theories and previous findings that political dispositions become settled by age 30. With the exception of some low-profile government spending questions, most policy questions show greater evidence of active updating than this question of ideological identification, though the overall level of active updating is still limited. Partisan identification, in contrast, showed the highest degree of active updating of all political questions, as well as some of the highest consistency, and this updating was active across all age ranges.

These results are consistent with theories that posit that, at least in the current era, ideological identification (view of oneself as liberal or conservative), rather than some other belief such as partisan identification, moral views, religion, or particular policy positions, is the "central" political belief [@boutylinevaisey; @converse].

It is important not to overstate the role of this belief in forming other beliefs. While our findings suggest that individuals appear to bring their partisan identification in line with their ideological identification, there is limited evidence of adjusting other beliefs. This pattern is most consistent with Baldassari and Gelman's [-@baldassarigelman] model of "partisans without constraint," which suggests that individuals hold a few strong beliefs and align their partisan identification with these, rather than adopting beliefs as a function of their partisan identification. 

Since there is no evidence of ideological change for the majority of the sample, and only very weak evidence of changes in specific policy positions, even high profile ones, the pattern of results is not consistent with the popular conception of political polarization in which individuals become more extreme in their views over time. This is notable given the time frame of our study, which covered the Obama administration, a time that is commonly assumed to observe a conservative shift for Republicans and a liberal shift for Democrats. Similarly, our findings are not consistent with the idea that individuals adopt a partisan affiliation based on their social groupings and subsequently adjust their ideological commitments to conform to that [@greenetal]. For this to be true, ideological identification and other political beliefs would have to demonstrate at least as much updating as partisan identification, which is not true in our data.

The finding that ideological identification is comparatively stable should not be taken to imply that most people in the population have the kind of tightly knit belief structures that political scientists typically call "ideologies." Outside of a handful of high-profile items such as partisan identity, abortion, and gay marriage, individuals appear to lack clear opinions on most specific policy questions. The low degree of consistency in beliefs is consistent with the idea that people are "ideologically innocent" [@kinderkalmoe]. What we can say is that individuals over 30 in American during the period we studied did not make lasting changes in whether and how strongly they thought of themselves as "liberal" or "conservative."

The overall picture that emerges from evaluating the active updating and stability of political items in the GSS is one in which the majority of respondents, especially those over 30 years old, hold a general political identity and a few clear views on issues like abortion, attempt to align their partisan identification to their views, and respond to elite opinion change when it provides clear signals. It is not a picture of a rapidly polarizing society or one wholly ignorant of public debates.

## Methodological Implications

Methodologically, our results highlight the challenges of evaluating population-wide attitude change using short-term panel studies. The evidence strongly suggests that most of what might be interpreted as "change" in the GSS panels is some combination of measurement error or non-persistent change. It does not matter whether measurement error or short-term change is the predominant driver behind this pattern; what matters is that substantive change is too rare in a sample of adults to measure accurately on the vast majority of items. This strongly argues against using two-wave panels to measure attitude change, which do not allow researchers to separate persisting from non-persisting changes. 

The fact that persistent change is practically nonexistent for many items bolsters the case for using repeated survey responses to measure the reliability of survey items [@alwin; @houthastings], since it is often a valid assumption that the underlying view is unchanging. At the same time, our results call for greater focus on methodological tools that can separate short-term attitude change from measurement error. While we generally assume that lasting changes in attitudes are more likely to influence behavior, this is not necessarily true. Short-term attitude changes might be meaningful in shaping short-term behaviors, but identifying it is difficult.

We said at the outset that patterns of change might be the result of panel conditioning, or that the process of participating in the survey leads to more active updating or stability than might be expected in the absence of survey participation. One could view our results through this prism and claim that items that exhibit high active updating and high consistency (such as views on gay marriage or partisan identification) do so because of panel conditioning bias, or that items that exhibit low active updating and high consistency (such as views on abortion or the legalization of marijuana) do so because of commitment bias, but it becomes difficult to explain why these biases operate for specific questions and not others. 

We believe the overall pattern of results we observe is more consistent with other theoretical models of belief change than those outlined by panel conditioning. We see too much inconsistency in responses for commitment bias to be a major explanatory factor. Items that we have theoretical reasons to suspect might succumb to the updating form of panel conditioning bias, such as questions where “respondents’ initial attitudes are less crystallized” [@warrenhalpernmanners: p. 499], questions that “increase respondents’ knowledge of the behavior and/or their motivation to engage in it” [@warrenhalpernmanners: p. 500], or questions that “induce respondents to provide socially non-normative or stigmatized responses” [@warrenhalpernmanners: p. 501], tend to show low active updating and low consistency.

We cannot (and would not want to) rule out the possibility that panel conditioning is taking place in the GSS. We believe it is worthwhile to explore these same GSS panels for evidence of panel conditioning. However, we do not believe that panel conditioning bias is the principal driver of the overall pattern of change and consistency we observe.

Because many attitudes, including views on abortion, race, gender roles, social trust, and institutional confidence, have mostly stabilized by the time individuals enter the GSS, our results also call for greater emphasis on surveying the attitudes of adolescents and children to understand how these attitudes are formed. Panel studies tracing the political socialization of adolescents are rare but could be highly fruitful. In a similar vein, it does not seem worthwhile to ask certain GSS questions repeatedly. Questions about racial stereotypes, which show almost no consistency from wave to wave but have been asked every wave since 1996, strike us as particularly problematic. Those that are repeated should be specifically targeted to topics that are believed to be changing broadly (e.g., politics, gay rights). 

Our results ultimately suggest that real, persistent attitude change is an uncommon phenomenon among adults. Understanding the social origins of individuals' attitudes requires greater focus on the "conditions of past production"—childhood and adolescence—that give rise to persistent beliefs in adulthood.


\pagebreak

# Appendix A: $\phi$ values for all variables

Figures \@ref(fig:religphi) through \@ref(fig:racgenphi) plot $\phi$ estimates for all items included in the analysis, grouped by subject material.

[Figures \@ref(fig:religphi) through \@ref(fig:racgenphi) about here.]

```{r loadfiguredata}
load(here("data", "figure_data.Rdata"))
```

# Appendix B: Coarsened variable estimates

```{r loadcoarse}
load(here("data", "coarse_vars.Rdata"))

```


Estiates of $\phi$ for coarsened items are presented in Figures \@ref(fig:coarserelig) through \@ref(fig:coarseracgen). If scales had symmetrical scales with no clear midpoint (e.g., strongly agree/agree/disagree/strongly disagree), we coarsened those scales to two points (agree/disagree). If scales included a clear midpoint, we included that and coarsened responses on either side. For items on large scales such as hours of TV watched, we split responses into greater than the median or less than or equal to the median. If changes between ends of each scale are more persistent than changes within ends of these scales, then $\phi$ estimates of coarsened item should be higher than estimates for items with more response options. 

[Figures \@ref(fig:coarserelig) through \@ref(fig:coarseracgen) about here.]

Generally speaking, most items with no evidence of active updating continue to have no evidence of active updating when coarsened. For items that showed evidence for active updating, the coarsened estimates tended to be very similar to the uncoarsened estimates, suggesting that persisting and non-persisting changes happen about as often between ends of these scales as they do within ends of these scales.

There are a couple notable departures from this general pattern. Several political questions -- general political views, views on whether the government should reduce inequality, and views on whether the government should help blacks -- show decreased evidence of persisting change when coarsened. This suggests that changes around the midpoint of the scale tend to be measurement error, a finding that is consistent with previous work suggesting that individuals without settled political views tend to choose points around the middle of the response scale [@converse].

\pagebreak

# References


```{r dag, message=FALSE, fig.width=5, fig.cap="Graphical representation of active updating and settled dispositions models over time."}
aum <- 
  dagitty("dag {
        y1 -> y2 -> y3 ;
        v1 -> y1 ;
        v2 -> y2 ;
        v3 -> y3 
        }")
coordinates( aum ) <-
  list( x=c(y1 = 1, y2 = 3, y3 = 5, v1 = 1, v2 = 3, v3 = 5),
        y=c(y1 = 2, y2 = 2, y3 = 2, v1 = 1, v2 = 1, v3 = 1) )

aum_dag <- aum %>% tidy_dagitty() %>% ggdag(node_size = 8) + 
  theme_dag_blank() + 
  labs(title = "Active Updating Model") +
  scale_y_continuous(limits = c(.8,3.2)) +
  scale_x_continuous(limits = c(.5, 5.5)) + 
  theme(plot.title = element_text(hjust = 0.5)) 


sdm <- 
  dagitty("dag {
        U -> {y1 y2 y3} ;
        v1 -> y1 ;
        v2 -> y2 ;
        v3 -> y3 
        }")
coordinates( sdm ) <-
  list( x=c(y1 = 1, y2 = 3, y3 = 5, v1 = 1, v2 = 3, v3 = 5, U = 3),
        y=c(y1 = 2, y2 = 2, y3 = 2, v1 = 1, v2 = 1, v3 = 1, U = 3) )

sdm_dag <- sdm %>% tidy_dagitty() %>% ggdag(node_size = 8) + 
  theme_dag_blank() + 
  labs(title = "Settled Dispositions Model") +
  scale_y_continuous(limits = c(.8,3.2)) +
    scale_x_continuous(limits = c(.5, 5.5)) + 
  theme(plot.title = element_text(hjust = 0.5)) 


gridExtra::grid.arrange(aum_dag, sdm_dag, nrow = 1)
```

```{r phihist, message=FALSE, fig.width=6.8, fig.cap="Distribution of phi estimates and probabilities that items show evidence of active updating."}

res.df %>%
  filter(grepl("_c", var)==FALSE) %>%
  select(var, p, prob_aum) %>%
  gather(key = "key", value = "value", -var) %>%
  mutate(key = recode(key, "p"="Phi estimates (Updating)", "prob_aum"="Probability of some active updating")) %>%
  ggplot(aes(x = value, y=..count../sum(..count..))) +
  geom_histogram(fill = "gray", color = "black", bins = 15) + 
  geom_vline(xintercept = .5, color = "black", linetype = 2) + 
  theme_classic() + 
  facet_wrap(~key, scales = "free_x") +
  expand_limits(x = 1) +
  labs(x = "", y = "Proportion of items") + 
  theme(axis.title=element_text(size=9))
```

```{r agegroupcomparison, message=FALSE, fig.width=6.8, fig.height=8, fig.cap="Comparison of phi estimates for individuals over and equal to or less than 30 years old, with 95 percent confidence intervals."}

load(here("data", "age_results.Rdata"))


bind_rows(age.results) %>%
  mutate(ci.lower = estimate - 1.96 * std.error,
         ci.upper = estimate + 1.96 * std.error) %>%
  left_join(attitude_vars) %>%
  mutate(age = recode(age, "old"="Over 30", "young"="30 & under")) %>%
  ggplot(aes(x = reorder(var.name, estimate), y = estimate, color = age)) + 
  geom_hline(yintercept = .5, color = "black", linetype = 2) + 
  geom_pointrange(aes(ymin = ci.lower, ymax = ci.upper)) + 
  coord_flip() + 
  theme_minimal() + 
  scale_color_manual(values = c("black", "gray")) + 
  labs(x = "", y = "Phi estimate (Updating)", color = "") +
  theme(axis.text=element_text(size=7),
        axis.title=element_text(size=9),
        legend.position = "bottom")

```

```{r phibetascatter, message=FALSE, fig.width=6.8, fig.height = 6.0, fig.cap="Distribution of beta and phi estimates for GSS items, by whether model prefers phi = .5 constraint."}
res.df %>%
  filter(grepl("_c", var)==FALSE) %>%
  mutate(aum = ifelse(var %in% aum_vars, "\nPersistent\nChange\n", "\nNo\nPersistent\nChange\n")) %>%
  ggplot(aes(x = p, y = b1)) + 
  geom_point(aes(fill = aum, shape = aum), alpha = .7) + 
  scale_shape_manual(values = c(21, 22)) + 
  scale_fill_manual(values = c("gray", "black")) + 
  geom_text_repel(data = label_vars, aes(label = var.name), size = 3) + 
  theme_minimal() +
  labs(x = "Phi estimate (Updating)", y = "Beta estimate (Consistency)", fill = "", shape = "") + 
  theme(axis.title=element_text(size=9))
```

```{r summary, message=FALSE, fig.width=6.8, fig.height=9.0, fig.cap="Summary of phi estimates for all items, by topical group. Numbers in parentheses indicate the number of items in each topical group."}
load(here("data", "summary_plot_data.Rdata"))

cat_counts <- attitude_vars %>% group_by(small.cat) %>% summarise(n = n())

plot.data %>%
  left_join(cat_counts) %>%
    mutate(small.cat = ifelse(small.cat == "Sex, sexuality & abortion",
                            "Sex, sexuality &\nabortion", small.cat),
           small.cat = ifelse(small.cat == "Guns, laws, crime & police",
                            "Guns, laws, crime &\npolice", small.cat),
          small.cat = ifelse(small.cat == "Confidence in leadership",
                            "Confidence in\nleadership", small.cat),
          small.cat = ifelse(small.cat == "Relig. identity & beliefs",
                            "Relig. identity &\nbeliefs", small.cat),
          var.name = ifelse(var.name == "Executive branch", "Exe. branch", 
                                   var.name)) %>%
  mutate(small.cat = paste(small.cat, " (", n, ")", sep = "")) %>%
  ggplot(aes(x = reorder(small.cat, median))) + 
  geom_pointrange(aes(y = median, ymin = q25, ymax = q75)) + 
  geom_point(aes(y = min), shape = 21) + 
  geom_point(aes(y = max),shape = 21) + 
  geom_text(aes(y = max, label = var.name), size = 2, position = position_nudge(y = .07)) + 
  coord_flip() + 
  theme_minimal() + 
  theme(
    strip.background = element_blank(),
    strip.text.x = element_blank(),
    strip.placement = "outside",
    legend.position = "none",
    legend.title = element_blank(),
    axis.text=element_text(size=7),
    legend.text=element_text(size=9)
    )  +
  expand_limits(y = .9) +
  labs(x = "", y = "Phi estimate (Updating)")

```

```{r polvariables, message=FALSE, fig.width=7, fig.height=8, fig.cap="Phi (updating) and beta (consistency) estimates for 43 political attitudes and identities."}
left_join(res.df, attitude_vars) %>%
  filter(small.cat %in% c("Politics & government", "Public spending",
                          "Sex, sexuality & abortion") |
           var %in% c("cappun", "divlaw", "gunlaw", "grass", "courts",
                      "letin1a")) %>%
  mutate(small.cat = ifelse(small.cat %in% c("Race & immigration", 
                                             "Guns, laws, crime & police") | 
                              var %in% c("prayer", "uswary"), 
         "Misc. policy" , small.cat)) %>%
  filter(var %!in% c("abscale6", "absingle", "teensex", "xmarsex",
                     "homosex", "premarsx")) %>%
  mutate(var.name = gsub("Government", "Gov't", var.name),
         var.name = gsub("Abortion", "Abort", var.name),
         small.cat = ifelse(small.cat == "Sex, sexuality & abortion",
                            "Abortion & sex", small.cat)) %>%
  mutate(small.cat = factor(small.cat, c("Politics & government", "Public spending",
                                        "Abortion & sex", "Misc. policy"))) %>%
  ggplot(aes(x = p, y = b1)) + 
  geom_vline(xintercept = .5, linetype = 2, color = "gray") + 
  geom_point(aes(fill = small.cat), shape = 21) + 
  geom_text_repel(aes(label = var.name), size = 1.75) + 
  theme_bw() + 
  labs(x = "Phi estimate (Updating)", y = "Beta estimate (Consistency)", fill = "", shape = "") + 
  theme(axis.title=element_text(size=9)) +
  facet_wrap(~small.cat) + 
  theme(legend.position = "none")

```

```{r religphi, message=FALSE, fig.width=6.8, fig.height=8.5, fig.cap="Phi estimates for items about religious activity and beliefs, social life, subjective SES, and suicide."}
clean.pestimates %>%
  filter(grepl("_c", var)==FALSE) %>%
  filter(small.cat %in% c("Relig. Activity", "Relig. identity & beliefs",
                          "Social life", "Subjective SES", "Suicide")) %>%
  ggplot(aes(x = reorder(var.name, estimate), y = estimate, color = as.factor(stable))) + 
  geom_hline(yintercept = .5, linetype = 2, color = "gray") + 
  geom_pointrange(aes(ymin = ci.lower, ymax = ci.upper)) + 
  geom_point() + 
  coord_flip() + 
  theme_minimal() + 
  facet_grid(small.cat ~ ., scales = "free_y", space = "free", switch = "both") + 
  scale_color_manual(values = c("black", "darkgray")) + 
  theme(
    strip.background = element_blank(),
    strip.text.x = element_blank(),
    strip.text.y =element_text(size=8),
    strip.placement = "outside",
    legend.position = "none",
    legend.title = element_blank(),
    axis.text=element_text(size=7),
    legend.text=element_text(size=7)
  )  +
  expand_limits(y = .9) +
  labs(x = "", y = "Phi estimate (Updating)")

```

```{r poliphi, message=FALSE, fig.width=6.8, fig.height=8.5, fig.cap="Phi estimates for items about guns, law, crime and policing; politics and government; and public spending. The item 'Police can hit citizens', which has phi = .43, has been removed for ease of viewing"}

clean.pestimates %>%
  filter(grepl("_c", var)==FALSE) %>%
  filter(small.cat %in% c("Guns, laws, crime & police", "Politics & government",
                          "Public spending")) %>%
  filter(var != "polhitok") %>%
  ggplot(aes(x = reorder(var.name, estimate), y = estimate, color = as.factor(stable))) + 
  geom_hline(yintercept = .5, linetype = 2, color = "gray") + 
  geom_pointrange(aes(ymin = ci.lower, ymax = ci.upper)) + 
  geom_point() + 
  coord_flip() + 
  theme_minimal() + 
  facet_grid(small.cat ~ ., scales = "free_y", space = "free", switch = "both") + 
  scale_color_manual(values = c("black", "darkgray")) + 
  theme(
    strip.background = element_blank(),
    strip.text.x = element_blank(),
        strip.text.y =element_text(size=8),
    strip.placement = "outside",
    legend.position = "none",
    legend.title = element_blank(),
    axis.text=element_text(size=7),
    legend.text=element_text(size=7)
  )  +
  expand_limits(y = .9) +
  labs(x = "", y = "Phi estimate (Updating)")

```

```{r civlibphi, message=FALSE, fig.width=6.8, fig.height=8.5, fig.cap="Phi estimates for items about civil liberties, confidence in leadership, health, morale, and social trust."}
clean.pestimates %>%
  filter(grepl("_c", var)==FALSE) %>%
  filter(small.cat %in% c("Civil liberties", "Trust", "Confidence in leadership",
                          "Health & morale")) %>%
  ggplot(aes(x = reorder(var.name, estimate), y = estimate, color = as.factor(stable))) + 
  geom_hline(yintercept = .5, linetype = 2, color = "gray") + 
  geom_pointrange(aes(ymin = ci.lower, ymax = ci.upper)) + 
  geom_point() + 
  coord_flip() + 
  theme_minimal() + 
  facet_grid(small.cat ~ ., scales = "free_y", space = "free", switch = "both") + 
  scale_color_manual(values = c("black", "darkgray")) + 
  theme(
    strip.background = element_blank(),
    strip.text.x = element_blank(),
            strip.text.y =element_text(size=8),
    strip.placement = "outside",
    legend.position = "none",
    legend.title = element_blank(),
    axis.text=element_text(size=7),
    legend.text=element_text(size=7)
  )  +
  expand_limits(y = .9) +
  labs(x = "", y = "Phi estimate (Updating)")
```


```{r racgenphi, message=FALSE, fig.width=6.8, fig.height=8.5, fig.cap="Phi estimates for items about race, gender, sex, sexuality, and abortion."}
clean.pestimates %>%
  filter(grepl("_c", var)==FALSE) %>%
  filter(small.cat %in% c("Gender & family", "Race & immigration", "Sex, sexuality & abortion")) %>%
  ggplot(aes(x = reorder(var.name, estimate), y = estimate, color = as.factor(stable))) + 
  geom_hline(yintercept = .5, linetype = 2, color = "gray") + 
  geom_pointrange(aes(ymin = ci.lower, ymax = ci.upper)) + 
  geom_point() + 
  coord_flip() + 
  theme_minimal() + 
  facet_grid(small.cat ~ ., scales = "free_y", space = "free", switch = "both") + 
  scale_color_manual(values = c("black", "darkgray")) + 
  theme(
    strip.background = element_blank(),
    strip.text.x = element_blank(),
                strip.text.y =element_text(size=8),
    strip.placement = "outside",
    legend.position = "none",
    legend.title = element_blank(),
    axis.text=element_text(size=7),
    legend.text=element_text(size=7)
  )  +
  expand_limits(y = .9) +
  labs(x = "", y = "Phi estimate (Updating)")

```


```{r coarserelig, message=FALSE, fig.width=6.8, fig.height=8.5, fig.cap="Phi estimates for coarsened questions about religion, subjective socioeconomic status, and morale." }
coarse_vars %>%
  filter(small.cat %in% c("Relig. Activity", "Relig. identity & beliefs",
                          "Social life", "Subjective SES", "Suicide",
                          "Health & morale")) %>%
  ggplot(aes(x = fct_rev(var.name), y = estimate, color = as.factor(stable))) + 
  geom_hline(yintercept = .5, linetype = 2, color = "gray") + 
  geom_pointrange(aes(ymin = ci.lower, ymax = ci.upper)) + 
  geom_point() + 
  coord_flip() + 
  theme_minimal() + 
  facet_grid(base_var ~ ., scales = "free_y", space = "free", switch = "both") + 
  scale_color_manual(values = c("black", "darkgray")) + 
  theme(
    strip.background = element_blank(),
    strip.text.x = element_blank(),
    strip.text.y = element_blank(),
    strip.placement = "outside",
    legend.position = "none",
    legend.title = element_blank(),
    axis.text=element_text(size=7),
    legend.text=element_text(size=7)
  )  +
  expand_limits(y = .9) +
  labs(x = "", y = "Phi estimate (Updating)")

```

```{r coarsepoli, message=FALSE, fig.width=6.8, fig.height=8.5, fig.cap="Phi estimates for coarsened questions about politics, government, sex and sexuality."}
coarse_vars %>%
  filter(small.cat %in% c("Guns, laws, crime & police", "Politics & government",
                          "Public spending", "Sex, sexuality & abortion")) %>%
  ggplot(aes(x = fct_rev(var.name), y = estimate, color = as.factor(stable))) + 
  geom_hline(yintercept = .5, linetype = 2, color = "gray") + 
  geom_pointrange(aes(ymin = ci.lower, ymax = ci.upper)) + 
  geom_point() + 
  coord_flip() + 
  theme_minimal() + 
  facet_grid(base_var ~ ., scales = "free_y", space = "free", switch = "both") + 
  scale_color_manual(values = c("black", "darkgray")) + 
  theme(
    strip.background = element_blank(),
    strip.text.x = element_blank(),
    strip.text.y = element_blank(),
    strip.placement = "outside",
    legend.position = "none",
    legend.title = element_blank(),
    axis.text=element_text(size=7),
    legend.text=element_text(size=7)
  )  +
  expand_limits(y = .9) +
  labs(x = "", y = "Phi estimate (Updating)")
```

```{r coarseracgen, message=FALSE, fig.width=6.8, fig.height=8.5, fig.cap="Phi estimates for coarsened questions about race and gender."}
coarse_vars %>%
  filter(small.cat %in% c("Gender & family", "Race & immigration")) %>%
  ggplot(aes(x = fct_rev(var.name), y = estimate, color = as.factor(stable))) + 
  geom_hline(yintercept = .5, linetype = 2, color = "gray") + 
  geom_pointrange(aes(ymin = ci.lower, ymax = ci.upper)) + 
  geom_point() + 
  coord_flip() + 
  theme_minimal() + 
  facet_grid(base_var ~ ., scales = "free_y", space = "free", switch = "both") + 
  scale_color_manual(values = c("black", "darkgray")) + 
  theme(
    strip.background = element_blank(),
    strip.text.x = element_blank(),
    strip.text.y = element_blank(),
    strip.placement = "outside",
    legend.position = "none",
    legend.title = element_blank(),
    axis.text=element_text(size=7),
    legend.text=element_text(size=7)
  )  +
  expand_limits(y = .9) +
  labs(x = "", y = "Phi estimate (Updating)")
```

